{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf # only for importing mnist dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example\n",
    "# Reading an image\n",
    "img = cv2.imread('messi.jpeg',cv2.IMREAD_GRAYSCALE)/255\n",
    "plt.imshow(img,cmap='gray')\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CONVOLUTION OPERATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class convolution_operations:\n",
    "\n",
    "    def __init__(self, num_filters, filter_size):\n",
    "        self.num_filters = num_filters\n",
    "        self.filter_size = filter_size\n",
    "        self.conv_filter = np.random.randn(num_filters,filter_size,filter_size)/(filter_size*filter_size)\n",
    "\n",
    "    def image_region(self, image):\n",
    "        height , width = image.shape\n",
    "        self.image = image\n",
    "        for j in range(height - self.filter_size + 1):\n",
    "            for k in range(width - self.filter_size + 1):\n",
    "                image_patch = image[ j : (j+self.filter_size), k : (k+self.filter_size)]\n",
    "                yield image_patch, j, k\n",
    "\n",
    "    def forward_propogation(self, image):\n",
    "        height , width = image.shape\n",
    "        conv_out = np.zeros((height - self.filter_size + 1, width - self.filter_size + 1, self.num_filters))\n",
    "        for image_patch, i, j in self.image_region(image):\n",
    "            conv_out[i,j] = np.sum(image_patch*self.conv_filter, axis = (1,2))\n",
    "        return conv_out\n",
    "        \n",
    "    def backward_propogation(self, dL_dout, learning_rate):\n",
    "        dL_dF_params = np.zeros(self.conv_filter.shape)\n",
    "        for image_patch, i, j in self.image_region(self.image):\n",
    "            for k in range(self.num_filters):\n",
    "                dL_dF_params[k] += image_patch*dL_dout[i,j,k]\n",
    "        self.conv_filter -= learning_rate*dL_dF_params\n",
    "        return dL_dF_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example to visualize the output of convolution operation\n",
    "conn = convolution_operations(18,7)\n",
    "out = conn.forward_propogation(img)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting the example (output of a convolution operation)\n",
    "plt.imshow(out[:,:,17], cmap='gray')\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MAX POOLING OPERATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Max_Pool:\n",
    "    def __init__(self,filter_size):\n",
    "        self.filter_size = filter_size\n",
    "\n",
    "    def image_region(self, image):\n",
    "        new_height = image.shape[0] // self.filter_size\n",
    "        new_width = image.shape[1] // self.filter_size\n",
    "        self.image = image\n",
    "\n",
    "        for i in range(new_height):\n",
    "            for j in range(new_width):\n",
    "                image_patch = image[(i * self.filter_size) : (i * self.filter_size + self.filter_size), (j * self.filter_size) : (j * self.filter_size + self.filter_size)]\n",
    "                yield image_patch, i, j\n",
    "\n",
    "    def forward_propogation(self, image):\n",
    "        height, width, num_filters = image.shape\n",
    "        output = np.zeros((height // self.filter_size, width // self.filter_size, num_filters))\n",
    "\n",
    "        for image_patch, i, j in self.image_region(image):\n",
    "            output[i,j] = np.max(image_patch, axis=(0,1))\n",
    "\n",
    "        return output\n",
    "    \n",
    "    def back_propogation(self, dL_dout):\n",
    "        dL_dmax_pool = np.zeros(self.image.shape)\n",
    "        for image_patch, i, j in self.image_region(self.image):\n",
    "            height, width, num_filters = image_patch.shape\n",
    "            maximum_val = np.amax(image_patch, axis = (0,1))\n",
    "\n",
    "            for i1 in range(height):\n",
    "                for j1 in range(width):\n",
    "                    for k1 in range(num_filters):\n",
    "                        if image_patch[i1,j1,k1] == maximum_val[k1]:\n",
    "                            dL_dmax_pool[i*self.filter_size + i1, j*self.filter_size + j1, k1] = dL_dout[i, j, k1]\n",
    "            \n",
    "        return dL_dmax_pool\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example to visualize the output of a maxpooling operation after convolution (output of convolution is fed as input to maxpooling forward propag)\n",
    "conn2 = Max_Pool(4)\n",
    "out2 = conn2.forward_propogation(out)\n",
    "out2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting the example (output of a maxpooling operation)\n",
    "plt.imshow(out2[:,:,17], cmap='gray')\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SOFTMAX OPERATION - ACTIVATION FUNCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Softmax:\n",
    "    \n",
    "    def __init__(self, input_node, softmax_node):\n",
    "        self.weight = np.random.randn(input_node,softmax_node)/input_node\n",
    "        self.bias = np.zeros(softmax_node)\n",
    "\n",
    "    def forward_propagation(self, image):\n",
    "        \n",
    "        self.orig_im_shape = image.shape # used in backpropagation\n",
    "        image_modified = image.flatten()\n",
    "        self.modified_input = image_modified # to be used in back propagtion\n",
    "        output_val = np.dot(image_modified, self.weight) + self.bias\n",
    "        self.out = output_val\n",
    "        exp_out = np.exp(output_val)\n",
    "        return exp_out/np.sum(exp_out, axis=0)\n",
    "    \n",
    "    def back_propagation(self, dL_dout, learning_rate):\n",
    "        for i, grad in enumerate(dL_dout):\n",
    "            if grad == 0:\n",
    "                continue\n",
    "\n",
    "            transformation_eq = np.exp(self.out)\n",
    "            S_total = np.sum(transformation_eq)\n",
    "\n",
    "            # Gradients with respect to out (z)\n",
    "            dy_dz = -transformation_eq[i]*transformation_eq / (S_total**2)\n",
    "            dy_dz[i] = transformation_eq[i]*(S_total - transformation_eq[i]) / (S_total**2)\n",
    "\n",
    "            # Gradients of totals against weights/biases/input\n",
    "            dz_dw = self.modified_input\n",
    "            dz_db = 1\n",
    "            dz_d_inp = self.weight\n",
    "\n",
    "            # Gradients of loss against totals\n",
    "            dL_dz = grad * dy_dz\n",
    "\n",
    "            # Gradients of loss against weights/biases/input\n",
    "            dL_dw = dz_dw[np.newaxis].T @ dL_dz[np.newaxis]\n",
    "            dL_db = dL_dz * dz_db\n",
    "            dL_d_inp = dz_d_inp @ dL_dz\n",
    "\n",
    "        self.weight -= learning_rate * dL_dw\n",
    "        self.bias -= learning_rate * dL_db\n",
    "\n",
    "        return dL_d_inp.reshape(self.orig_im_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example is passed to softmax after maxpooling operation - Here it gets flattened into number of linear dimension (nodes or classes)\n",
    "conn3 = Softmax(373*248*18,10)\n",
    "out3 = conn3.forward_propagation(out2)\n",
    "print(out3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IMPLEMENTATION (TRAINING WITH ACTUAL DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the mnist dataset from tensorflow\n",
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "# Split dataset into training and testing data\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing the shape of dataset for understanding\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Among the number of datas, we take 1500 datas for both training and testing\n",
    "train_images = x_train[:1500]\n",
    "train_labels = y_train[:1500]\n",
    "test_images = x_test[:1500]\n",
    "test_labels = y_test[:1500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating instances of convolution, maxppoling and activation layers\n",
    "conv = convolution_operations(8,3)\n",
    "pool = Max_Pool(2)\n",
    "softmax = Softmax(13*13*8,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_forward_prop(image,label):\n",
    "\n",
    "    out_p = conv.forward_propogation((image/255)-0.5)\n",
    "    out_p = pool.forward_propogation(out_p)\n",
    "    out_p = softmax.forward_propagation(out_p)\n",
    "\n",
    "    cross_ent_loss = -np.log(out_p[label])\n",
    "    accuracy_eval = 1 if np.argmax(out_p) == label else 0\n",
    "\n",
    "    return out_p, cross_ent_loss, accuracy_eval\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_cnn(image, label, learn_rate=.005):\n",
    "\n",
    "    # Forward\n",
    "    out, loss, acc = cnn_forward_prop(image, label)\n",
    "\n",
    "    # calculate initial gradient\n",
    "    gradient = np.zeros(10)\n",
    "    gradient[label] = -1 / out[label]\n",
    "\n",
    "    # Backpropagation\n",
    "    grad_back = softmax.back_propagation(gradient, learn_rate)\n",
    "    grad_back = pool.back_propogation(grad_back)\n",
    "    grad_back = conv.backward_propogation(grad_back, learn_rate)\n",
    "\n",
    "    return loss, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 --->\n",
      "1 steps out of 100 steps: AVerage Loss 0.000 and Accuracy: 0%\n",
      "101 steps out of 100 steps: AVerage Loss 2.246 and Accuracy: 16%\n",
      "201 steps out of 100 steps: AVerage Loss 2.039 and Accuracy: 33%\n",
      "301 steps out of 100 steps: AVerage Loss 1.611 and Accuracy: 51%\n",
      "401 steps out of 100 steps: AVerage Loss 1.162 and Accuracy: 65%\n",
      "501 steps out of 100 steps: AVerage Loss 1.072 and Accuracy: 71%\n",
      "601 steps out of 100 steps: AVerage Loss 0.819 and Accuracy: 76%\n",
      "701 steps out of 100 steps: AVerage Loss 0.723 and Accuracy: 74%\n",
      "801 steps out of 100 steps: AVerage Loss 0.783 and Accuracy: 73%\n",
      "901 steps out of 100 steps: AVerage Loss 0.613 and Accuracy: 84%\n",
      "1001 steps out of 100 steps: AVerage Loss 0.679 and Accuracy: 75%\n",
      "1101 steps out of 100 steps: AVerage Loss 0.726 and Accuracy: 76%\n",
      "1201 steps out of 100 steps: AVerage Loss 0.518 and Accuracy: 82%\n",
      "1301 steps out of 100 steps: AVerage Loss 0.461 and Accuracy: 86%\n",
      "1401 steps out of 100 steps: AVerage Loss 0.582 and Accuracy: 83%\n",
      "Epoch 2 --->\n",
      "1 steps out of 100 steps: AVerage Loss 0.000 and Accuracy: 0%\n",
      "101 steps out of 100 steps: AVerage Loss 0.557 and Accuracy: 84%\n",
      "201 steps out of 100 steps: AVerage Loss 0.522 and Accuracy: 83%\n",
      "301 steps out of 100 steps: AVerage Loss 0.338 and Accuracy: 90%\n",
      "401 steps out of 100 steps: AVerage Loss 0.515 and Accuracy: 86%\n",
      "501 steps out of 100 steps: AVerage Loss 0.385 and Accuracy: 90%\n",
      "601 steps out of 100 steps: AVerage Loss 0.459 and Accuracy: 86%\n",
      "701 steps out of 100 steps: AVerage Loss 0.444 and Accuracy: 87%\n",
      "801 steps out of 100 steps: AVerage Loss 0.573 and Accuracy: 82%\n",
      "901 steps out of 100 steps: AVerage Loss 0.723 and Accuracy: 75%\n",
      "1001 steps out of 100 steps: AVerage Loss 0.652 and Accuracy: 82%\n",
      "1101 steps out of 100 steps: AVerage Loss 0.449 and Accuracy: 89%\n",
      "1201 steps out of 100 steps: AVerage Loss 0.421 and Accuracy: 87%\n",
      "1301 steps out of 100 steps: AVerage Loss 0.462 and Accuracy: 87%\n",
      "1401 steps out of 100 steps: AVerage Loss 0.368 and Accuracy: 89%\n",
      "Epoch 3 --->\n",
      "1 steps out of 100 steps: AVerage Loss 0.000 and Accuracy: 0%\n",
      "101 steps out of 100 steps: AVerage Loss 0.349 and Accuracy: 87%\n",
      "201 steps out of 100 steps: AVerage Loss 0.350 and Accuracy: 87%\n",
      "301 steps out of 100 steps: AVerage Loss 0.524 and Accuracy: 88%\n",
      "401 steps out of 100 steps: AVerage Loss 0.377 and Accuracy: 92%\n",
      "501 steps out of 100 steps: AVerage Loss 0.530 and Accuracy: 85%\n",
      "601 steps out of 100 steps: AVerage Loss 0.354 and Accuracy: 89%\n",
      "701 steps out of 100 steps: AVerage Loss 0.356 and Accuracy: 87%\n",
      "801 steps out of 100 steps: AVerage Loss 0.298 and Accuracy: 88%\n",
      "901 steps out of 100 steps: AVerage Loss 0.499 and Accuracy: 86%\n",
      "1001 steps out of 100 steps: AVerage Loss 0.363 and Accuracy: 84%\n",
      "1101 steps out of 100 steps: AVerage Loss 0.341 and Accuracy: 91%\n",
      "1201 steps out of 100 steps: AVerage Loss 0.426 and Accuracy: 88%\n",
      "1301 steps out of 100 steps: AVerage Loss 0.501 and Accuracy: 83%\n",
      "1401 steps out of 100 steps: AVerage Loss 0.388 and Accuracy: 90%\n",
      "Epoch 4 --->\n",
      "1 steps out of 100 steps: AVerage Loss 0.000 and Accuracy: 0%\n",
      "101 steps out of 100 steps: AVerage Loss 0.249 and Accuracy: 95%\n",
      "201 steps out of 100 steps: AVerage Loss 0.454 and Accuracy: 84%\n",
      "301 steps out of 100 steps: AVerage Loss 0.248 and Accuracy: 94%\n",
      "401 steps out of 100 steps: AVerage Loss 0.381 and Accuracy: 87%\n",
      "501 steps out of 100 steps: AVerage Loss 0.222 and Accuracy: 94%\n",
      "601 steps out of 100 steps: AVerage Loss 0.188 and Accuracy: 93%\n",
      "701 steps out of 100 steps: AVerage Loss 0.462 and Accuracy: 89%\n",
      "801 steps out of 100 steps: AVerage Loss 0.344 and Accuracy: 89%\n",
      "901 steps out of 100 steps: AVerage Loss 0.306 and Accuracy: 94%\n",
      "1001 steps out of 100 steps: AVerage Loss 0.365 and Accuracy: 87%\n",
      "1101 steps out of 100 steps: AVerage Loss 0.375 and Accuracy: 86%\n",
      "1201 steps out of 100 steps: AVerage Loss 0.416 and Accuracy: 91%\n",
      "1301 steps out of 100 steps: AVerage Loss 0.431 and Accuracy: 90%\n",
      "1401 steps out of 100 steps: AVerage Loss 0.282 and Accuracy: 90%\n",
      "**Testing Phase\n",
      "Test Loss :  0.51648431069227\n",
      "Test Accuracy :  0.8353333333333334\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(4):\n",
    "    print(f\"Epoch {epoch+1} --->\")\n",
    "\n",
    "    #shuffle the training data\n",
    "    shuffle_data = np.random.permutation(len(train_images))\n",
    "    train_images = train_images[shuffle_data]\n",
    "    train_labels = train_labels[shuffle_data]\n",
    "\n",
    "    #Training the cnn\n",
    "    loss = 0\n",
    "    num_correct = 0\n",
    "    for i, (im, label) in enumerate(zip(train_images, train_labels)):\n",
    "        if i % 100 == 0:\n",
    "            print(f\"{i+1} steps out of 100 steps: AVerage Loss {loss/100:.3f} and Accuracy: {num_correct}%\")\n",
    "            loss = 0\n",
    "            num_correct = 0\n",
    "        \n",
    "        l1, accu = training_cnn(im,label)\n",
    "        loss += l1\n",
    "        num_correct += accu\n",
    "\n",
    "print(\"**Testing Phase\")\n",
    "loss = 0\n",
    "num_correct = 0\n",
    "for im, label in zip(test_images, test_labels):\n",
    "    _, l1, accu = cnn_forward_prop(im, label)\n",
    "    loss += l1\n",
    "    num_correct += accu\n",
    "\n",
    "num_tests = len(test_images)\n",
    "print('Test Loss : ', loss/num_tests)\n",
    "print('Test Accuracy : ', num_correct/num_tests)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
